{
  "requirements": [
    {
      "id": "REQ_000",
      "description": "The system must integrate OpenAI Deep Research API using the Responses API with o3-deep-research and o4-mini-deep-research models for autonomous research capabilities",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_000.1",
          "description": "Configure the OpenAI Responses API endpoint (POST https://api.openai.com/v1/responses) for Deep Research capabilities with proper authentication, request formatting, and model selection between o3-deep-research and o4-mini-deep-research",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "API route created at /api/tools/deep-research/route.ts following existing POST route pattern",
            "OpenAI client correctly instantiated with API key validation at request time",
            "Request body properly formatted with model, input array (developer/user roles), reasoning config, and tools array",
            "Model selection supports both o3-deep-research-2025-06-26 and o4-mini-deep-research-2025-06-26",
            "Default model is o4-mini for cost optimization with option to upgrade to o3 for thorough research",
            "API key stored in OPENAI_API_KEY environment variable and validated using existing env.ts Zod schema",
            "Request includes proper Content-Type: application/json header",
            "Response parsing correctly extracts report text from response.output[-1].content[0].text",
            "Citations extracted from response.output[-1].content[0].annotations with title and url fields",
            "Error responses follow existing pattern with code, message, and retryable fields"
          ],
          "implementation": {
            "frontend": [
              "Create DeepResearchPanel.tsx component for research query input and results display",
              "Add research depth selector (quick/thorough) mapped to model selection",
              "Display loading state with estimated time message (can take tens of minutes)",
              "Render research results with markdown formatting and citation links",
              "Show cost estimate before execution (~$3 for quick, ~$30 for thorough)"
            ],
            "backend": [
              "Create /api/tools/deep-research/route.ts with POST handler",
              "Implement DeepResearchRequestSchema Zod validation for query, depth, and tool options",
              "Create OpenAI Responses API request builder function",
              "Implement response parser to extract report text and citations",
              "Add reasoning summary extraction from intermediate steps",
              "Implement exponential backoff retry logic following existing pattern (MAX_RETRIES=3)"
            ],
            "middleware": [
              "Validate OPENAI_API_KEY exists before processing request",
              "Implement request timeout handling for long-running operations",
              "Add rate limiting tracking per user/session"
            ],
            "shared": [
              "Define DeepResearchRequest interface with query, depth, and tool configurations",
              "Define DeepResearchResponse interface with text, citations[], reasoning summary",
              "Define Citation interface with title, url, and snippet fields",
              "Add DeepResearchError custom error class extending existing error pattern",
              "Define DeepResearchDepth type as 'quick' | 'thorough'"
            ]
          },
          "testable_properties": [],
          "function_id": "DeepResearchService.configureResponsesApiEndpoint",
          "related_concepts": [
            "OpenAI Responses API",
            "API Authentication",
            "Model Selection",
            "Request Configuration",
            "Environment Variables"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.2",
          "description": "Implement support for the web_search_preview tool configuration enabling Deep Research to perform internet searches with configurable domains, search context size, and user location options",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "web_search_preview tool included in tools array of Responses API request",
            "domains parameter accepts array of allowed domains for search filtering (e.g., ['arxiv.org', 'nature.com'])",
            "search_context_size parameter configurable with values: 'low', 'medium', 'high' affecting search depth",
            "user_location parameter accepts optional location object with country and region for localized results",
            "Default configuration uses no domain restrictions and medium search context",
            "Tool configuration validated using Zod schema before API request",
            "Web search calls tracked in response for cost estimation ($0.01 per call)",
            "Search query logging available in response.output for debugging",
            "Domain allowlist stored as configurable constant for different research contexts"
          ],
          "implementation": {
            "frontend": [
              "Create WebSearchConfig.tsx component for advanced search settings",
              "Add domain filter input with preset options (academic, news, general)",
              "Implement search context size dropdown (low/medium/high)",
              "Optional location selector for region-specific research",
              "Display search queries performed in research results panel"
            ],
            "backend": [
              "Create WebSearchToolConfig interface matching OpenAI schema",
              "Implement buildWebSearchToolConfig() function to construct tool object",
              "Add domain validation to ensure valid URL patterns",
              "Create preset configurations for common research domains (ACADEMIC_DOMAINS, NEWS_DOMAINS)",
              "Track web_search_call events in response for cost calculation"
            ],
            "middleware": [
              "Validate domain list contains valid domain strings",
              "Sanitize user_location input to prevent injection",
              "Log search configuration for audit purposes"
            ],
            "shared": [
              "Define WebSearchToolConfig interface with domains, search_context_size, user_location",
              "Define SearchContextSize type as 'low' | 'medium' | 'high'",
              "Define UserLocation interface with country and optional region",
              "Create DOMAIN_PRESETS constant object with academic, news, tech domain arrays",
              "Add web_search_preview to ToolType union type"
            ]
          },
          "testable_properties": [],
          "function_id": "DeepResearchService.configureWebSearchTool",
          "related_concepts": [
            "Web Search Tool",
            "Domain Filtering",
            "Search Context",
            "User Location",
            "Tool Configuration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.3",
          "description": "Implement support for the code_interpreter tool enabling Deep Research to execute Python code during research for data analysis, calculations, and visualization generation",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "code_interpreter tool included in tools array when data analysis is required",
            "Tool requires no additional configuration parameters (simple inclusion)",
            "Code execution outputs captured from response for display to user",
            "Code interpreter session costs tracked ($0.03 per session)",
            "Generated visualizations (if any) extracted and stored via Vercel Blob",
            "Code snippets displayed in research results with syntax highlighting",
            "Error handling for code execution failures included in response parsing",
            "Option to enable/disable code interpreter per research request",
            "Intermediate code execution steps visible in reasoning summary"
          ],
          "implementation": {
            "frontend": [
              "Add toggle for 'Enable code analysis' in research options",
              "Create CodeOutputDisplay.tsx component for rendering code and results",
              "Implement syntax highlighting for code snippets using existing or new library",
              "Display any generated charts/visualizations as images",
              "Show code execution status in research progress indicator"
            ],
            "backend": [
              "Add code_interpreter to tools array when enableCodeAnalysis=true",
              "Implement extractCodeExecutions() function to parse code_interpreter outputs",
              "Handle file outputs from code interpreter (charts, data files)",
              "Upload generated files to Vercel Blob storage",
              "Track code interpreter session usage for cost calculation"
            ],
            "middleware": [
              "No additional middleware required - code runs in OpenAI sandbox"
            ],
            "shared": [
              "Define CodeExecutionResult interface with code, output, files array",
              "Add code_interpreter to ToolType union type",
              "Define GeneratedFile interface with filename, blob_url, mime_type",
              "Add enableCodeAnalysis boolean to DeepResearchRequest interface"
            ]
          },
          "testable_properties": [],
          "function_id": "DeepResearchService.configureCodeInterpreterTool",
          "related_concepts": [
            "Code Interpreter",
            "Python Execution",
            "Data Analysis",
            "Code Output",
            "Session Management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.4",
          "description": "Implement support for the file_search tool enabling Deep Research to search through uploaded documents using vector store IDs for context-aware research across user-provided materials",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "file_search tool included in tools array with vector_store_ids configuration",
            "Support for maximum 2 vector store IDs per request (OpenAI limit)",
            "Vector store ID validation ensures valid format before API call",
            "Integration with existing Vercel Blob upload flow for document storage",
            "Vector store creation workflow documented for user-uploaded documents",
            "File search results included in citations with source document references",
            "Error handling for invalid or inaccessible vector store IDs",
            "Clear user feedback when file search is enabled but no stores configured",
            "Support for pre-configured project-level vector stores"
          ],
          "implementation": {
            "frontend": [
              "Create VectorStoreSelector.tsx component for choosing/managing stores",
              "Add document upload flow that creates vector store entries",
              "Display which documents are included in research context",
              "Show file search source in citation display (document name, page)",
              "Implement vector store management panel for project settings"
            ],
            "backend": [
              "Create /api/tools/vector-stores/route.ts for store management",
              "Implement createVectorStore() function using OpenAI Vector Stores API",
              "Add uploadToVectorStore() function for adding documents",
              "Build file_search tool config with vector_store_ids array",
              "Validate vector store IDs exist and are accessible before research request",
              "Parse file_search annotations to include document source in citations"
            ],
            "middleware": [
              "Validate vector_store_ids array length <= 2",
              "Verify user has access to specified vector stores",
              "Handle vector store expiration/deletion gracefully"
            ],
            "shared": [
              "Define FileSearchToolConfig interface with vector_store_ids array",
              "Define VectorStore interface with id, name, created_at, file_count",
              "Add file_search to ToolType union type",
              "Define VectorStoreFile interface with id, filename, status",
              "Add vectorStoreIds optional array to DeepResearchRequest interface"
            ]
          },
          "testable_properties": [],
          "function_id": "DeepResearchService.configureFileSearchTool",
          "related_concepts": [
            "File Search",
            "Vector Store",
            "Document Search",
            "RAG",
            "Embeddings"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_000.5",
          "description": "Implement background mode handling with polling mechanism for long-running Deep Research tasks that can take tens of minutes, including status tracking, progress updates, and result retrieval",
          "type": "sub_process",
          "parent_id": "REQ_000",
          "children": [],
          "acceptance_criteria": [
            "Research requests sent with background: true parameter for async execution",
            "Response includes task ID for polling status and retrieving results",
            "Polling endpoint created at /api/tools/deep-research/[taskId]/route.ts",
            "Polling interval starts at 5 seconds, increases with exponential backoff up to 30 seconds",
            "Progress status extracted from intermediate reasoning steps during polling",
            "Research state persisted in Zustand store with taskId, status, progress, and partial results",
            "User can navigate away and return to see research progress",
            "Abort/cancel functionality implemented to stop ongoing research",
            "Maximum polling duration of 30 minutes before timeout error",
            "Completed research results cached to avoid re-fetching",
            "Failed research shows error message with retry option"
          ],
          "implementation": {
            "frontend": [
              "Create ResearchProgressTracker.tsx component showing status and progress",
              "Implement useResearchPolling custom hook for managing poll lifecycle",
              "Add progress bar with estimated completion percentage",
              "Display intermediate reasoning summaries as research progresses",
              "Show cancel button to abort long-running research",
              "Persist research task state across page navigation using Zustand",
              "Implement toast notifications for research completion/failure",
              "Add 'View Research' button in notification to navigate to results"
            ],
            "backend": [
              "Implement /api/tools/deep-research/route.ts to initiate background research",
              "Create /api/tools/deep-research/[taskId]/route.ts for status polling",
              "Store taskId mapping to OpenAI response ID for retrieval",
              "Implement getResearchStatus() function calling OpenAI to check completion",
              "Extract progress indicators from response.output reasoning steps",
              "Create /api/tools/deep-research/[taskId]/cancel/route.ts for abort",
              "Implement result caching in memory or KV store for completed research"
            ],
            "middleware": [
              "Validate taskId format before polling",
              "Implement rate limiting on polling requests (max 1 per 3 seconds)",
              "Add request deduplication to prevent multiple simultaneous polls",
              "Track polling attempts and enforce maximum duration"
            ],
            "shared": [
              "Define ResearchTaskStatus enum: 'pending', 'in_progress', 'completed', 'failed', 'cancelled'",
              "Define ResearchTask interface with taskId, status, progress, createdAt, result",
              "Add researchTasks Map to Zustand store state",
              "Define PollingConfig interface with initialInterval, maxInterval, maxDuration",
              "Create POLLING_CONFIG constant with default values",
              "Add BlockingOperationType 'research' to existing type union",
              "Define ResearchProgress interface with percentage, currentStep, estimatedTimeRemaining"
            ]
          },
          "testable_properties": [],
          "function_id": "DeepResearchService.handleBackgroundModePolling",
          "related_concepts": [
            "Background Jobs",
            "Polling",
            "Webhooks",
            "Long-running Tasks",
            "Progress Tracking",
            "Abort Handling"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_001",
      "description": "The system must integrate OpenAI Image Creation API using gpt-image-1.5 model for generating images from text prompts",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_001.1",
          "description": "Configure the Images API endpoint to POST to https://api.openai.com/v1/images/generations with proper authentication, request handling, and response processing for the gpt-image-1.5 model",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "API route is created at /api/tools/generate-image/route.ts",
            "Endpoint accepts POST requests with JSON body containing prompt and optional parameters",
            "OpenAI API key is securely accessed from environment variables (OPENAI_API_KEY)",
            "Request uses gpt-image-1.5 model as the default model",
            "Response always handles base64 format (gpt-image models ALWAYS return base64, not URLs)",
            "Base64 image data is decoded and uploaded to Vercel Blob for persistence",
            "Blob URL is returned to client for display and download",
            "Rate limiting with exponential backoff is implemented (matching existing transcribe pattern: 10s base delay)",
            "Network errors trigger retry with 2s base exponential backoff (max 3 attempts)",
            "Proper error codes returned: RATE_LIMIT, INVALID_REQUEST, API_ERROR, TIMEOUT",
            "Request timeout is set appropriately (recommend 60s for image generation)",
            "Content moderation rejections are handled gracefully with user-friendly messages"
          ],
          "implementation": {
            "frontend": [
              "Create ImageGenerationService class in frontend/src/lib/tools/imageGeneration.ts",
              "Add handleImageGeneration function that calls /api/tools/generate-image endpoint",
              "Implement loading state management for image generation (can take 10-30 seconds)",
              "Display generated image in chat using blob URL",
              "Add download button for generated images",
              "Handle and display revised_prompt if returned by API"
            ],
            "backend": [
              "Create /api/tools/generate-image/route.ts API endpoint",
              "Initialize OpenAI client with API key from environment",
              "Call openai.images.generate() with model: 'gpt-image-1.5'",
              "Decode b64_json response using Buffer.from(result.data[0].b64_json, 'base64')",
              "Upload decoded buffer to Vercel Blob with appropriate content-type header",
              "Return JSON response with blob URL, filename, and optional revised_prompt",
              "Implement retry logic matching existing transcribe/route.ts pattern"
            ],
            "middleware": [
              "Validate request body schema (prompt required, parameters optional)",
              "Verify API key is configured before processing request",
              "Add request size limits (prompts can be up to 32K characters)",
              "Log API usage for cost tracking and monitoring"
            ],
            "shared": [
              "Define ImageGenerationRequest interface with prompt, size, quality, output_format, background fields",
              "Define ImageGenerationResponse interface with imageUrl, filename, revisedPrompt fields",
              "Define ImageGenerationError interface matching ToolError pattern",
              "Add image generation constants (MAX_PROMPT_LENGTH: 32000, DEFAULT_TIMEOUT: 60000)"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageGenerationAPI.configureEndpoint",
          "related_concepts": [
            "OpenAI SDK",
            "API Route Handler",
            "Base64 Image Processing",
            "Vercel Blob Storage",
            "Error Handling",
            "Rate Limiting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.2",
          "description": "Support image size options including 1024x1024, 1536x1024 (landscape), 1024x1536 (portrait), and auto mode that lets the model choose optimal dimensions",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Size parameter accepts exactly these values: '1024x1024', '1536x1024', '1024x1536', 'auto'",
            "Default size is '1024x1024' when not specified",
            "Invalid size values are rejected with descriptive error message",
            "UI provides dropdown/radio selection for size options with visual aspect ratio indicators",
            "1024x1024 is labeled as 'Square (1:1)' in UI",
            "1536x1024 is labeled as 'Landscape (3:2)' in UI",
            "1024x1536 is labeled as 'Portrait (2:3)' in UI",
            "auto is labeled as 'Auto (AI chooses)' in UI",
            "Selected size is persisted in user preferences (optional feature)",
            "API request correctly passes size parameter to OpenAI",
            "Response image dimensions match requested size (or are appropriate for 'auto')"
          ],
          "implementation": {
            "frontend": [
              "Create ImageSizeSelector component with visual aspect ratio previews",
              "Add size option to image generation form/dialog",
              "Display selected dimensions in pixels below selector",
              "Show thumbnail preview of aspect ratio for each option",
              "Store last-used size preference in localStorage",
              "Validate size selection before enabling generate button"
            ],
            "backend": [
              "Add size parameter validation in API route using enum/union type",
              "Pass validated size to openai.images.generate() call",
              "Handle 'auto' mode - pass as-is to API, OpenAI determines optimal size",
              "Log selected size for analytics and cost tracking"
            ],
            "middleware": [
              "Validate size is one of allowed values, reject with 400 if invalid",
              "Transform size parameter if needed for API compatibility"
            ],
            "shared": [
              "Define IMAGE_SIZES constant array: ['1024x1024', '1536x1024', '1024x1536', 'auto']",
              "Define ImageSize type as union of valid size strings",
              "Define SIZE_LABELS mapping for UI display names",
              "Add helper function getAspectRatio(size: ImageSize): string"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageGenerationAPI.configureSizeOptions",
          "related_concepts": [
            "Image Dimensions",
            "Aspect Ratio",
            "Form Validation",
            "User Preferences",
            "Responsive Design"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.3",
          "description": "Support quality levels (low, medium, high) that affect image detail, generation time, and cost with appropriate user guidance on tradeoffs",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Quality parameter accepts exactly these values: 'low', 'medium', 'high'",
            "Default quality is 'high' when not specified (best user experience)",
            "Invalid quality values are rejected with descriptive error message",
            "UI displays quality options with estimated cost and generation time",
            "Low quality shows ~$0.01 estimated cost, fastest generation",
            "Medium quality shows ~$0.04 estimated cost, moderate generation time",
            "High quality shows ~$0.17 estimated cost, longest generation time",
            "Quality selection UI includes visual quality comparison examples if feasible",
            "Cost estimates are displayed before user confirms generation",
            "API request correctly passes quality parameter to OpenAI",
            "Quality affects actual generation result as expected"
          ],
          "implementation": {
            "frontend": [
              "Create QualitySelector component with radio buttons or segmented control",
              "Display cost estimate next to each quality level",
              "Add tooltip explaining quality tradeoffs (detail vs speed vs cost)",
              "Show warning icon for 'high' quality with cost note",
              "Recommend 'medium' as balanced option with '(Recommended)' label",
              "Store quality preference in localStorage",
              "Update cost estimate display when quality changes"
            ],
            "backend": [
              "Add quality parameter validation in API route",
              "Pass validated quality to openai.images.generate() call",
              "Log quality selection for cost analytics",
              "Track actual API costs per quality level for monitoring"
            ],
            "middleware": [
              "Validate quality is one of allowed values",
              "Optionally implement cost tracking/budgeting middleware"
            ],
            "shared": [
              "Define QUALITY_LEVELS constant array: ['low', 'medium', 'high']",
              "Define ImageQuality type as union of valid quality strings",
              "Define QUALITY_COST_ESTIMATES mapping: { low: 0.01, medium: 0.04, high: 0.17 }",
              "Define QUALITY_DESCRIPTIONS for UI display"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageGenerationAPI.configureQualityLevels",
          "related_concepts": [
            "Image Quality",
            "Cost Optimization",
            "Generation Speed",
            "User Experience",
            "Pricing Tiers"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.4",
          "description": "Support output formats (png, jpeg, webp) with appropriate handling for transparency, compression, and browser compatibility",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Output format parameter accepts exactly these values: 'png', 'jpeg', 'webp'",
            "Default output format is 'png' when not specified (supports transparency)",
            "Invalid format values are rejected with descriptive error message",
            "PNG format preserves transparency when background is 'transparent'",
            "JPEG format is recommended when transparency is not needed (smaller file)",
            "WebP format offers best compression while maintaining quality",
            "Correct MIME type is set when uploading to Vercel Blob (image/png, image/jpeg, image/webp)",
            "Generated filename includes correct extension (.png, .jpg, .webp)",
            "UI explains format differences and recommendations",
            "Format selection is disabled/hidden when background='transparent' and format='jpeg' (incompatible)"
          ],
          "implementation": {
            "frontend": [
              "Create FormatSelector component with format options",
              "Display file size estimates per format",
              "Show transparency compatibility warning when jpeg selected with transparent background",
              "Auto-switch to PNG if user selects transparent background with JPEG format",
              "Add download button that uses correct file extension",
              "Display format in image metadata/info panel"
            ],
            "backend": [
              "Add output_format parameter validation in API route",
              "Pass validated output_format to openai.images.generate() call",
              "Set correct Content-Type header when uploading to Vercel Blob",
              "Generate filename with correct extension based on format",
              "Handle format-specific processing if needed"
            ],
            "middleware": [
              "Validate output_format is one of allowed values",
              "Validate format/background compatibility (jpeg cannot have transparent background)",
              "Return 400 error if incompatible combination requested"
            ],
            "shared": [
              "Define OUTPUT_FORMATS constant array: ['png', 'jpeg', 'webp']",
              "Define ImageOutputFormat type as union of valid format strings",
              "Define FORMAT_MIME_TYPES mapping: { png: 'image/png', jpeg: 'image/jpeg', webp: 'image/webp' }",
              "Define FORMAT_EXTENSIONS mapping: { png: '.png', jpeg: '.jpg', webp: '.webp' }",
              "Add helper function isFormatCompatibleWithBackground(format, background): boolean"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageGenerationAPI.configureOutputFormats",
          "related_concepts": [
            "Image Formats",
            "Transparency Support",
            "File Compression",
            "Browser Compatibility",
            "MIME Types"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_001.5",
          "description": "Support background options (auto, transparent, opaque) for image generation with appropriate format compatibility handling",
          "type": "sub_process",
          "parent_id": "REQ_001",
          "children": [],
          "acceptance_criteria": [
            "Background parameter accepts exactly these values: 'auto', 'transparent', 'opaque'",
            "Default background is 'auto' when not specified (AI chooses based on prompt)",
            "Invalid background values are rejected with descriptive error message",
            "Transparent background generates PNG or WebP format image with alpha channel",
            "Transparent background selection auto-switches format from JPEG to PNG",
            "Opaque background ensures solid background (white or contextually appropriate)",
            "Auto mode lets AI determine if transparency is appropriate based on prompt content",
            "UI displays visual examples of transparent vs opaque backgrounds",
            "Warning displayed when transparent selected but JPEG format is chosen",
            "Generated image correctly reflects background selection",
            "Transparent images render correctly in UI with checkerboard background pattern"
          ],
          "implementation": {
            "frontend": [
              "Create BackgroundSelector component with visual toggle/radio options",
              "Show checkerboard preview for transparent option",
              "Show solid color preview for opaque option",
              "Add 'Auto' option with AI icon indicating automatic detection",
              "Display transparency compatibility warning with JPEG format",
              "Render generated transparent images on checkerboard background to show transparency",
              "Add CSS for checkerboard transparency indicator background"
            ],
            "backend": [
              "Add background parameter validation in API route",
              "Pass validated background to openai.images.generate() call",
              "Validate format/background compatibility before API call",
              "Auto-correct format to PNG if transparent background requested with JPEG",
              "Log background selection for analytics"
            ],
            "middleware": [
              "Validate background is one of allowed values",
              "Implement compatibility check: if background='transparent' and format='jpeg', return error or auto-correct",
              "Add warning header if auto-correction was applied"
            ],
            "shared": [
              "Define BACKGROUND_OPTIONS constant array: ['auto', 'transparent', 'opaque']",
              "Define ImageBackground type as union of valid background strings",
              "Define BACKGROUND_COMPATIBLE_FORMATS mapping: { transparent: ['png', 'webp'], opaque: ['png', 'jpeg', 'webp'], auto: ['png', 'jpeg', 'webp'] }",
              "Add helper function validateBackgroundFormatCompatibility(background, format): ValidationResult"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageGenerationAPI.configureBackgroundOptions",
          "related_concepts": [
            "Image Transparency",
            "Alpha Channel",
            "Background Removal",
            "Format Compatibility",
            "Design Assets"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_002",
      "description": "The system must implement document generation for PDF, DOCX, and XLSX formats using AI-generated structured content with document libraries",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_002.1",
          "description": "Implement OpenAI Structured Outputs with json_schema response format for document content generation that produces type-safe, schema-validated content structures for PDF, DOCX, and XLSX documents",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Creates OpenAI API call using response_format with type 'json_schema'",
            "Defines JSON schemas for each document type (PDF sections, DOCX paragraphs/headings, XLSX rows/columns)",
            "Schema includes required fields: title, sections/content array, metadata",
            "Validates generated content against schema before returning",
            "Handles schema validation errors with meaningful error messages",
            "Supports custom schema injection for flexible document structures",
            "Returns typed DocumentContent interface matching the schema",
            "Implements retry logic with exponential backoff for API failures",
            "Logs token usage for cost tracking",
            "PDF schema includes: title, author, sections with heading/content/subsections",
            "DOCX schema includes: title, paragraphs with style/text/formatting",
            "XLSX schema includes: sheetName, headers, rows with typed cells (string/number/date)"
          ],
          "implementation": {
            "frontend": [
              "Create DocumentContentPreview component to display generated content before export",
              "Add loading spinner during content generation with progress indication",
              "Implement content editing capability after generation but before document creation",
              "Show estimated cost before generation based on prompt length"
            ],
            "backend": [
              "Create POST /api/tools/generate-content route accepting prompt and documentType",
              "Implement generateStructuredContent() function in lib/tools/structuredOutputs.ts",
              "Define JSON schemas in lib/schemas/documentSchemas.ts for PDF, DOCX, XLSX",
              "Add schema validation using Zod to validate OpenAI response matches expected schema",
              "Implement retry logic following existing pattern from generate/route.ts",
              "Add error class StructuredOutputError extending existing error pattern"
            ],
            "middleware": [
              "Validate documentType is one of 'pdf', 'docx', 'xlsx'",
              "Validate prompt is non-empty and under token limit (32K chars)",
              "Rate limit structured output requests (cost management)"
            ],
            "shared": [
              "Define DocumentContent interface in lib/types.ts",
              "Define PDFContent, DOCXContent, XLSXContent specific interfaces",
              "Create DocumentSection, DocumentParagraph, SpreadsheetRow types",
              "Add ContentGenerationOptions interface with model, temperature, maxTokens",
              "Export JSON schema constants for reuse across services"
            ]
          },
          "testable_properties": [],
          "function_id": "StructuredOutputsService.generateDocumentContent",
          "related_concepts": [
            "OpenAI API",
            "JSON Schema",
            "Structured Outputs",
            "Type Safety",
            "Content Generation",
            "Response Validation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.2",
          "description": "Integrate PDFKit library for programmatic PDF generation that converts AI-generated structured content into professionally formatted PDF documents with support for text, headings, images, tables, and custom styling",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Installs pdfkit and @types/pdfkit as dependencies",
            "Creates PDF documents from PDFContent structured data",
            "Supports document metadata: title, author, subject, keywords",
            "Implements heading hierarchy (H1-H6) with appropriate font sizes and weights",
            "Renders paragraphs with configurable line spacing and margins",
            "Creates tables with headers, rows, borders, and cell padding",
            "Supports bullet lists and numbered lists",
            "Handles page breaks intelligently (avoid orphan headings)",
            "Supports embedded images with sizing and positioning",
            "Generates table of contents from heading structure",
            "Applies consistent styling via PDFStyle configuration object",
            "Returns PDF as Buffer for upload to Vercel Blob",
            "Handles Unicode characters and special fonts",
            "Adds page numbers in footer",
            "Supports custom fonts registration"
          ],
          "implementation": {
            "frontend": [
              "Add PDF export button to ButtonRibbon component",
              "Create PDFPreview component using PDF.js for in-browser preview",
              "Show PDF generation progress indicator",
              "Implement download trigger after blob URL is returned",
              "Add PDF styling options modal (margins, font size, orientation)"
            ],
            "backend": [
              "Create POST /api/tools/generate-document route",
              "Implement createPDF() function in lib/tools/pdfGenerator.ts",
              "Create PDFStyleConfig interface for consistent styling",
              "Build renderSection(), renderTable(), renderList() helper functions",
              "Handle buffer streaming to Vercel Blob",
              "Generate unique filenames with timestamp",
              "Clean up blob after configurable retention period"
            ],
            "middleware": [
              "Validate PDFContent structure before generation",
              "Limit document size (max pages configurable)",
              "Validate image URLs before embedding"
            ],
            "shared": [
              "Define PDFContent interface extending DocumentContent",
              "Create PDFSection type with heading, content, subsections",
              "Define PDFTable type with headers, rows, styling",
              "Add PDFStyle interface for fonts, colors, margins",
              "Export default PDF style constants"
            ]
          },
          "testable_properties": [],
          "function_id": "PDFGeneratorService.createPDF",
          "related_concepts": [
            "PDFKit",
            "PDF Generation",
            "Document Formatting",
            "Typography",
            "Tables",
            "Images",
            "Page Layout"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.3",
          "description": "Integrate docx library for Word document creation that converts AI-generated structured content into Microsoft Word compatible documents with proper styling, headings, tables, and formatting",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Installs docx library as dependency",
            "Creates DOCX documents from DOCXContent structured data",
            "Implements document properties: title, author, description, company",
            "Supports heading styles (Heading1 through Heading6)",
            "Creates styled paragraphs with alignment, spacing, indentation",
            "Implements bold, italic, underline, strikethrough inline formatting",
            "Creates tables with merged cells, borders, and shading",
            "Supports bullet points and numbered lists with nesting",
            "Adds images with text wrapping options",
            "Creates hyperlinks within document text",
            "Generates automatic table of contents",
            "Supports custom style definitions",
            "Returns DOCX as Buffer (via Packer.toBuffer)",
            "Handles page breaks and section breaks",
            "Supports headers and footers with page numbers"
          ],
          "implementation": {
            "frontend": [
              "Add DOCX export button to ButtonRibbon component",
              "Create document format selection dropdown (PDF/DOCX/XLSX)",
              "Show DOCX generation progress indicator",
              "Implement download with proper .docx extension",
              "Add DOCX styling options (font family, page orientation)"
            ],
            "backend": [
              "Extend POST /api/tools/generate-document to handle docx type",
              "Implement createDOCX() function in lib/tools/docxGenerator.ts",
              "Build paragraph builder with TextRun formatting support",
              "Create table builder with cell merging support",
              "Implement list builder with bullet/number style options",
              "Handle Packer.toBuffer() for binary output",
              "Upload generated buffer to Vercel Blob"
            ],
            "middleware": [
              "Validate DOCXContent structure before generation",
              "Sanitize text content (remove invalid XML characters)",
              "Validate image references exist before embedding"
            ],
            "shared": [
              "Define DOCXContent interface extending DocumentContent",
              "Create DOCXParagraph type with text, style, formatting",
              "Define DOCXTable type with rows, columns, merges",
              "Add DOCXStyle interface for document-level styling",
              "Create InlineFormatting type for bold/italic/underline"
            ]
          },
          "testable_properties": [],
          "function_id": "DOCXGeneratorService.createDOCX",
          "related_concepts": [
            "docx library",
            "Word Documents",
            "OOXML",
            "Document Styles",
            "Paragraph Formatting",
            "Tables"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.4",
          "description": "Integrate ExcelJS library for Excel spreadsheet generation that converts AI-generated structured content into Microsoft Excel compatible spreadsheets with multiple sheets, formatting, formulas, and charts",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Installs exceljs library as dependency",
            "Creates XLSX workbooks from XLSXContent structured data",
            "Supports multiple worksheets within single workbook",
            "Implements column headers with freeze pane",
            "Creates data rows with proper type handling (string, number, date, boolean)",
            "Supports cell formatting: fonts, fills, borders, alignment",
            "Implements number formatting (currency, percentage, decimals)",
            "Creates formulas for sum, average, count operations",
            "Supports conditional formatting rules",
            "Adds data validation dropdowns",
            "Creates basic charts (bar, line, pie) from data ranges",
            "Implements auto-filter on header rows",
            "Sets column widths automatically or explicitly",
            "Returns XLSX as Buffer (via workbook.xlsx.writeBuffer)",
            "Supports cell merging for headers"
          ],
          "implementation": {
            "frontend": [
              "Add XLSX export button to ButtonRibbon component",
              "Create spreadsheet preview component showing first N rows",
              "Allow column configuration before export",
              "Show row count and sheet names in preview",
              "Implement download with proper .xlsx extension"
            ],
            "backend": [
              "Extend POST /api/tools/generate-document to handle xlsx type",
              "Implement createXLSX() function in lib/tools/xlsxGenerator.ts",
              "Build worksheet builder with row/column handling",
              "Create cell formatter for different data types",
              "Implement formula builder for basic calculations",
              "Add chart builder for common chart types",
              "Handle workbook.xlsx.writeBuffer() for binary output",
              "Upload generated buffer to Vercel Blob"
            ],
            "middleware": [
              "Validate XLSXContent structure before generation",
              "Validate data types match schema expectations",
              "Limit sheet count and row count for performance"
            ],
            "shared": [
              "Define XLSXContent interface extending DocumentContent",
              "Create XLSXSheet type with name, headers, rows",
              "Define XLSXCell type with value, type, format, formula",
              "Add XLSXStyle interface for workbook-level styling",
              "Create ChartConfig type for chart generation options"
            ]
          },
          "testable_properties": [],
          "function_id": "XLSXGeneratorService.createXLSX",
          "related_concepts": [
            "ExcelJS",
            "Excel Spreadsheets",
            "XLSX",
            "Cell Formatting",
            "Formulas",
            "Data Validation",
            "Charts"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_002.5",
          "description": "Support template-based generation using Docxtemplater for pre-designed templates that allow users to create documents from professionally designed Word/Excel templates with AI-populated placeholder data",
          "type": "sub_process",
          "parent_id": "REQ_002",
          "children": [],
          "acceptance_criteria": [
            "Installs docxtemplater and pizzip libraries as dependencies",
            "Loads DOCX/XLSX template files from storage",
            "Parses template to identify all placeholder variables ({variable_name})",
            "Uses AI (Structured Outputs) to generate data matching template variables",
            "Performs variable substitution with error handling for missing variables",
            "Supports loop/repeat sections for arrays ({#items}...{/items})",
            "Supports conditional sections ({#if condition}...{/if})",
            "Handles image placeholders with {%image} syntax",
            "Validates generated data matches expected template structure",
            "Supports nested objects and arrays in data",
            "Returns filled document as Buffer",
            "Provides template upload capability for custom templates",
            "Includes built-in templates for common document types (invoice, report, letter)",
            "Shows preview of available placeholders before generation",
            "Handles template versioning for updates"
          ],
          "implementation": {
            "frontend": [
              "Create TemplateSelector component showing available templates",
              "Build TemplateUpload component for custom template files",
              "Show placeholder variables from selected template",
              "Create data input form based on template placeholders",
              "Add template preview modal showing template layout",
              "Implement template management UI (list, delete, rename)"
            ],
            "backend": [
              "Create POST /api/templates/upload for template storage",
              "Create GET /api/templates to list available templates",
              "Create GET /api/templates/:id/placeholders to extract variables",
              "Create POST /api/tools/generate-from-template route",
              "Implement parseTemplatePlaceholders() in lib/tools/templateParser.ts",
              "Implement fillTemplate() in lib/tools/templateGenerator.ts",
              "Store templates in Vercel Blob with metadata in database/JSON",
              "Build schema dynamically from template placeholders for AI generation"
            ],
            "middleware": [
              "Validate uploaded templates are valid DOCX/XLSX files",
              "Validate template size limits (max 10MB)",
              "Validate data completeness against required placeholders",
              "Sanitize template filenames"
            ],
            "shared": [
              "Define Template interface with id, name, type, placeholders, blobUrl",
              "Create TemplatePlaceholder type with name, type, required, defaultValue",
              "Define TemplateData interface as Record<string, unknown>",
              "Add LoopSection and ConditionalSection types",
              "Export BUILT_IN_TEMPLATES constant array with default templates"
            ]
          },
          "testable_properties": [],
          "function_id": "TemplateService.generateFromTemplate",
          "related_concepts": [
            "Docxtemplater",
            "Templates",
            "Placeholders",
            "Mail Merge",
            "Template Management",
            "Variable Substitution"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_003",
      "description": "The system must implement an intent classification layer to route natural language requests to appropriate tools",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_003.1",
          "description": "Create intent classifier using GPT-4o-mini with JSON response format to analyze user messages and determine the appropriate tool to route requests",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Classifier uses GPT-4o-mini model with response_format set to json_object",
            "System prompt clearly defines classification rules for each tool category",
            "Request includes conversation context (last 5 messages) for better classification",
            "Response is validated against a JSON schema before processing",
            "Classification completes within 2 seconds for typical requests",
            "Classifier handles empty or malformed user messages gracefully",
            "Rate limiting and retry logic follows existing pattern (MAX_RETRIES=3, exponential backoff)",
            "Unit tests cover all intent categories with at least 90% accuracy on test dataset"
          ],
          "implementation": {
            "frontend": [
              "Create IntentIndicator component to show detected intent before tool execution",
              "Add loading state in MessageInput while classification is in progress",
              "Display intent confidence as visual indicator (color-coded badge)"
            ],
            "backend": [
              "Create /api/tools/classify/route.ts endpoint accepting POST with {message, history} body",
              "Implement classifyIntent function in frontend/src/lib/intentClassifier.ts",
              "Define system prompt with clear classification rules and examples for each category",
              "Parse and validate JSON response using zod schema",
              "Return ClassifiedIntent type: {tool: ToolIntent, confidence: number, extractedParams: Record<string, unknown>}"
            ],
            "middleware": [
              "Add request validation for message and history fields",
              "Implement caching layer to avoid re-classifying identical messages",
              "Add telemetry to track classification accuracy and latency"
            ],
            "shared": [
              "Define ToolIntent type: 'deep_research' | 'image_generation' | 'document_generation' | 'chat_completion'",
              "Create ClassifiedIntent interface in frontend/src/lib/types.ts",
              "Define IntentClassificationError class extending existing error pattern",
              "Create JSON schema for response validation"
            ]
          },
          "testable_properties": [],
          "function_id": "IntentClassifierService.classifyIntent",
          "related_concepts": [
            "OpenAI Structured Outputs",
            "JSON Schema Validation",
            "Natural Language Understanding",
            "Tool Routing"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.2",
          "description": "Classify intents into four specific categories: deep_research, image_generation, document_generation, and chat_completion based on trigger phrases and semantic analysis",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "deep_research category triggers for: 'research', 'investigate', 'find out', 'analyze', 'what is the latest', 'compare'",
            "image_generation category triggers for: 'create image', 'draw', 'generate picture', 'visualize', 'make art', 'illustrate'",
            "document_generation category triggers for: 'create PDF', 'generate report', 'make spreadsheet', 'write document', 'export to Word/Excel'",
            "chat_completion is the default fallback for general conversation and writing assistance",
            "Classifier distinguishes between 'write a story' (chat_completion) and 'create a PDF of a story' (document_generation)",
            "Multi-intent messages are handled by identifying the primary intent (e.g., 'research X and create a PDF' prioritizes document_generation with research as content source)",
            "Category mappings are configurable via toolRegistry without code changes"
          ],
          "implementation": {
            "frontend": [
              "Create ToolCategoryIcon component to visually represent each category",
              "Add category filter dropdown in chat interface for manual override",
              "Display detected category with tool-specific styling before execution"
            ],
            "backend": [
              "Create toolRegistry.ts with Map<string, ToolDefinition> structure",
              "Define ToolDefinition interface: {name, description, triggerPhrases, handler, responseType}",
              "Implement trigger phrase matching as fallback when confidence is low",
              "Create category-specific system prompt sections with examples",
              "Add support for compound intents with primary/secondary classification"
            ],
            "middleware": [
              "Add category validation to ensure returned tool exists in registry",
              "Implement feature flag to enable/disable specific tool categories",
              "Log all classifications for analysis and model improvement"
            ],
            "shared": [
              "Define ToolDefinition interface in frontend/src/lib/toolRegistry.ts",
              "Create TOOL_CATEGORIES constant with category metadata",
              "Define CompoundIntent type for multi-tool requests: {primary: ToolIntent, secondary?: ToolIntent, chainMode: 'sequential' | 'parallel'}"
            ]
          },
          "testable_properties": [],
          "function_id": "IntentClassifierService.categorizeToTools",
          "related_concepts": [
            "Intent Categories",
            "Semantic Classification",
            "Trigger Phrases",
            "Tool Registry"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.3",
          "description": "Return confidence scores (0.0-1.0) for intent classification to enable informed routing decisions and clarification requests",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Confidence score is a float between 0.0 and 1.0 inclusive",
            "GPT-4o-mini is prompted to provide confidence as part of structured output",
            "Confidence reflects semantic clarity of the request relative to tool categories",
            "Responses include confidence scores for all categories (not just the winning one)",
            "Low confidence (<0.6) triggers different UX behavior than high confidence (>=0.8)",
            "Confidence calculation accounts for ambiguous phrases and hedging language",
            "System logs confidence distribution for model calibration analysis"
          ],
          "implementation": {
            "frontend": [
              "Create ConfidenceIndicator component showing score as percentage or bar",
              "Color-code confidence: red (<0.5), yellow (0.5-0.7), green (>0.7)",
              "Add tooltip explaining confidence meaning to users",
              "Show alternative classifications when confidence is moderate (0.5-0.7)"
            ],
            "backend": [
              "Extend JSON schema to require confidence field as number 0-1",
              "Prompt GPT-4o-mini to explain confidence reasoning in optional field",
              "Implement softmax-style scoring across all categories when using function calling",
              "Add confidence calibration logic based on historical accuracy data"
            ],
            "middleware": [
              "Add confidence threshold configuration via environment variable (INTENT_CONFIDENCE_THRESHOLD)",
              "Log confidence scores alongside classification results for analysis",
              "Implement A/B testing framework for confidence threshold optimization"
            ],
            "shared": [
              "Extend ClassifiedIntent interface with allScores: Record<ToolIntent, number>",
              "Define ConfidenceLevel type: 'low' | 'medium' | 'high'",
              "Create getConfidenceLevel utility function mapping scores to levels"
            ]
          },
          "testable_properties": [],
          "function_id": "IntentClassifierService.calculateConfidence",
          "related_concepts": [
            "Confidence Scoring",
            "Probability Distribution",
            "Classification Uncertainty",
            "Decision Thresholds"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.4",
          "description": "Extract relevant parameters from user messages for tool execution including entities, specifications, and constraints",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Extract image parameters: subject, style, size preference, quality preference, background preference",
            "Extract research parameters: topic, depth (quick/thorough), time constraints, source preferences",
            "Extract document parameters: format (pdf/docx/xlsx), title, sections, content source",
            "Extract temporal entities: dates, deadlines, time ranges mentioned in request",
            "Handle explicit parameter specifications: 'in high quality', '1024x1024 size', 'as a PDF'",
            "Parameters are returned as typed Record<string, unknown> with tool-specific keys",
            "Missing required parameters are flagged for clarification",
            "Parameters preserve user's exact wording for subjects and content descriptions"
          ],
          "implementation": {
            "frontend": [
              "Create ParameterPreview component showing extracted params before execution",
              "Add inline editing capability for extracted parameters",
              "Show parameter suggestions based on tool requirements",
              "Implement parameter validation feedback (e.g., invalid size format)"
            ],
            "backend": [
              "Define per-tool parameter schemas: ImageParams, ResearchParams, DocumentParams",
              "Extend system prompt to extract parameters as part of classification",
              "Implement parameter normalization (e.g., '4k' \u2192 '1024x1024')",
              "Add parameter inference logic for commonly omitted values",
              "Create validateParameters function for each tool type"
            ],
            "middleware": [
              "Sanitize extracted text parameters to prevent injection",
              "Validate parameter values against allowed ranges/enums",
              "Log extracted parameters for quality monitoring"
            ],
            "shared": [
              "Define ImageGenerationParams interface: {prompt, size?, quality?, background?, count?}",
              "Define DeepResearchParams interface: {query, depth?, tools?, maxDuration?}",
              "Define DocumentGenerationParams interface: {type, title?, sections?, contentSource?, template?}",
              "Create ToolParams union type combining all parameter interfaces"
            ]
          },
          "testable_properties": [],
          "function_id": "IntentClassifierService.extractParameters",
          "related_concepts": [
            "Named Entity Recognition",
            "Parameter Extraction",
            "Slot Filling",
            "Structured Information Extraction"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_003.5",
          "description": "Implement confidence thresholds for clarification requests when intent is ambiguous, providing users with options to confirm or clarify their request",
          "type": "sub_process",
          "parent_id": "REQ_003",
          "children": [],
          "acceptance_criteria": [
            "Confidence threshold for automatic routing is configurable (default: 0.75)",
            "Requests below threshold trigger clarification UI instead of immediate execution",
            "Clarification presents top 2-3 likely intents with descriptions",
            "Users can select intended tool or rephrase their request",
            "Clarification includes example phrases for each suggested tool",
            "System remembers user corrections to improve future classifications",
            "High-cost tools (deep_research) have higher confirmation threshold (0.85)",
            "Users can disable clarification prompts via settings (expert mode)"
          ],
          "implementation": {
            "frontend": [
              "Create ClarificationDialog component with tool options as buttons",
              "Show confidence scores for each option in clarification UI",
              "Add 'Just chat' option for users who don't want tool execution",
              "Implement quick-select keyboard shortcuts (1-4) for options",
              "Add 'Remember this choice' checkbox for similar future requests",
              "Create ExpertModeToggle in settings to disable clarifications"
            ],
            "backend": [
              "Define threshold configuration per tool in toolRegistry",
              "Create /api/tools/clarify endpoint for follow-up classification",
              "Implement user preference storage for classification corrections",
              "Add feedback loop API to record user selections for model improvement",
              "Create generateClarificationOptions function returning top-N alternatives"
            ],
            "middleware": [
              "Add INTENT_MIN_CONFIDENCE and INTENT_HIGH_COST_THRESHOLD env vars",
              "Implement rate limiting for clarification requests (prevent loops)",
              "Track clarification frequency as quality metric"
            ],
            "shared": [
              "Define ClarificationOption interface: {tool, confidence, description, examples}",
              "Create ClarificationRequest type: {originalMessage, options, selectedTool?}",
              "Define UserPreference interface for storing classification corrections",
              "Add isHighCostTool utility function checking tool pricing tier"
            ]
          },
          "testable_properties": [],
          "function_id": "IntentClassifierService.handleLowConfidence",
          "related_concepts": [
            "Clarification Dialogue",
            "Disambiguation",
            "User Confirmation",
            "Threshold Configuration"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_004",
      "description": "The system must implement a tool registry and routing system to dispatch requests to appropriate handlers",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_004.1",
          "description": "Create ToolDefinition interface with name, description, triggerPhrases, handler, and responseType properties to define the contract for all tools in the system",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Interface includes 'name' as string for display purposes",
            "Interface includes 'description' as string explaining tool purpose",
            "Interface includes 'triggerPhrases' as string[] containing keywords that activate the tool",
            "Interface includes 'handler' as async function type: (params: ToolParams) => Promise<ToolResult>",
            "Interface includes 'responseType' as union type: 'text' | 'image' | 'file'",
            "ToolParams generic interface defined with required 'query' and optional parameters",
            "ToolResult interface defined with discriminated union based on responseType",
            "TextResult contains { type: 'text', content: string, citations?: Citation[] }",
            "ImageResult contains { type: 'image', imageUrl: string, revisedPrompt?: string }",
            "FileResult contains { type: 'file', fileUrl: string, filename: string, mimeType: string }",
            "ToolError class extends Error with code, retryable, and suggestedAction properties",
            "Error codes defined as union: 'RATE_LIMIT' | 'INVALID_REQUEST' | 'API_ERROR' | 'TIMEOUT' | 'NOT_FOUND'",
            "All interfaces exported from frontend/src/lib/tools/types.ts",
            "JSDoc comments provided for all interfaces and properties"
          ],
          "implementation": {
            "frontend": [],
            "backend": [],
            "middleware": [],
            "shared": [
              "Create frontend/src/lib/tools/types.ts with all interface definitions",
              "Define ToolDefinition interface with all required properties",
              "Define ToolParams base interface with optional generic extension",
              "Define ToolResult as discriminated union (TextResult | ImageResult | FileResult)",
              "Define ToolError class extending Error with typed error codes",
              "Define Citation interface with title, url, and optional snippet",
              "Export ToolType as 'deep_research' | 'image_generation' | 'document_generation' | 'chat_completion'",
              "Define ToolExecutionContext with projectId, userId, and messageHistory"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolRegistry.ToolDefinition",
          "related_concepts": [
            "TypeScript interfaces",
            "discriminated unions",
            "handler functions",
            "response types",
            "tool metadata"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.2",
          "description": "Implement tool registry as Map<string, ToolDefinition> with pre-registered handlers for deep_research, image_generation, and document_generation tools",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Registry implemented as Map<ToolType, ToolDefinition> for type-safe lookups",
            "deep_research tool registered with triggerPhrases: ['research', 'investigate', 'find out about', 'analyze', 'study']",
            "image_generation tool registered with triggerPhrases: ['create image', 'draw', 'generate picture', 'visualize', 'artwork', 'illustration']",
            "document_generation tool registered with triggerPhrases: ['create document', 'generate report', 'make spreadsheet', 'create pdf', 'create excel', 'create word']",
            "chat_completion tool registered as fallback with responseType 'text'",
            "getTool(name: ToolType): ToolDefinition | undefined method implemented",
            "getAllTools(): ToolDefinition[] method implemented for tool discovery",
            "getToolByTrigger(phrase: string): ToolDefinition | undefined method with fuzzy matching",
            "Registry exported as singleton from frontend/src/lib/tools/registry.ts",
            "Each registered tool has unique name that matches its ToolType",
            "Handler functions are imported from separate files (lazy loading ready)"
          ],
          "implementation": {
            "frontend": [],
            "backend": [],
            "middleware": [],
            "shared": [
              "Create frontend/src/lib/tools/registry.ts as main registry module",
              "Implement toolRegistry as Map<ToolType, ToolDefinition>",
              "Create getTool() function with type-safe lookup",
              "Create getAllTools() function returning array of all tools",
              "Create getToolByTrigger() with case-insensitive phrase matching",
              "Import handler stubs from frontend/src/lib/tools/handlers/index.ts",
              "Register deep_research with DeepResearchHandler reference",
              "Register image_generation with ImageGenerationHandler reference",
              "Register document_generation with DocumentGenerationHandler reference",
              "Register chat_completion with ChatCompletionHandler as default"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolRegistry.toolRegistry",
          "related_concepts": [
            "Map data structure",
            "singleton pattern",
            "handler registration",
            "tool discovery",
            "lazy loading"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.3",
          "description": "Support response types text, image, and file with appropriate rendering components and download capabilities",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Text responses rendered as markdown with citation links",
            "Image responses displayed inline with download button",
            "File responses shown as download card with filename and size",
            "Images stored in Vercel Blob and returned as URL",
            "Documents stored in Vercel Blob with 24-hour expiry",
            "MIME type correctly set: application/pdf, application/vnd.openxmlformats-officedocument.wordprocessingml.document, application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            "Response type determines Message component rendering branch",
            "ToolResultRenderer component handles all three response types",
            "Loading states shown during tool execution",
            "Error states displayed with retry option when retryable=true",
            "Citations rendered as clickable links opening in new tab"
          ],
          "implementation": {
            "frontend": [
              "Create frontend/src/components/tools/ToolResultRenderer.tsx as main result component",
              "Create TextResultView component with markdown rendering and citations",
              "Create ImageResultView component with inline image and download button",
              "Create FileResultView component with download card UI",
              "Create ToolLoadingState component with progress indicator",
              "Create ToolErrorState component with error message and retry button",
              "Update Message component to detect tool results and render ToolResultRenderer",
              "Add download helper function using blob URLs"
            ],
            "backend": [
              "Create utility to upload tool results to Vercel Blob",
              "Set appropriate Content-Disposition headers for downloads",
              "Configure blob expiry policies per response type"
            ],
            "middleware": [],
            "shared": [
              "Define ResponseTypeConfig interface with render hints",
              "Create MIME_TYPES constant map for file types",
              "Define DownloadableResult interface for file/image responses"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolRegistry.responseTypeHandlers",
          "related_concepts": [
            "response serialization",
            "file downloads",
            "image display",
            "blob storage",
            "MIME types"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.4",
          "description": "Create API routes under /api/tools/ for classify, deep-research, generate-image, and generate-document endpoints",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "/api/tools/classify POST accepts { message: string } and returns { tool: ToolType, confidence: number, params: object }",
            "/api/tools/deep-research POST accepts { query: string, depth?: 'quick' | 'thorough' } and returns research results",
            "/api/tools/generate-image POST accepts { prompt: string, size?: string, quality?: string } and returns image URL",
            "/api/tools/generate-document POST accepts { type: 'pdf' | 'docx' | 'xlsx', contentPrompt: string, template?: string } and returns file URL",
            "All routes validate request body with Zod schemas",
            "All routes return consistent error format: { error: string, code: string, retryable: boolean }",
            "Status codes follow existing pattern: 401 for auth, 429 for rate limit, 500 for API errors",
            "Deep research route supports background: true for long-running tasks",
            "Deep research returns polling URL when background=true",
            "/api/tools/deep-research/[id] GET route for polling background task status",
            "Image generation route handles base64 response and uploads to Vercel Blob",
            "Document generation route creates file using appropriate library and uploads to Vercel Blob",
            "All routes log errors to console with request ID for debugging"
          ],
          "implementation": {
            "frontend": [],
            "backend": [
              "Create frontend/src/app/api/tools/classify/route.ts with intent classification",
              "Create frontend/src/app/api/tools/deep-research/route.ts with OpenAI Responses API",
              "Create frontend/src/app/api/tools/deep-research/[id]/route.ts for polling",
              "Create frontend/src/app/api/tools/generate-image/route.ts with GPT Image API",
              "Create frontend/src/app/api/tools/generate-document/route.ts with document libraries",
              "Implement Zod schemas for each route's request validation",
              "Create shared error response utility function",
              "Implement OpenAI client initialization with API key from env",
              "Handle rate limiting with exponential backoff (existing pattern)",
              "Add request ID generation for error tracking"
            ],
            "middleware": [
              "Add API key validation middleware for all /api/tools routes",
              "Implement rate limiting per route (configurable limits)",
              "Add request logging middleware with timing"
            ],
            "shared": [
              "Create frontend/src/lib/tools/api-schemas.ts with Zod validation schemas",
              "Define ClassifyRequest, DeepResearchRequest, ImageRequest, DocumentRequest schemas",
              "Create shared response builder utility"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolRoutes.apiRoutes",
          "related_concepts": [
            "Next.js API routes",
            "request validation",
            "error handling",
            "rate limiting",
            "OpenAI API integration"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_004.5",
          "description": "Support multi-tool chains for combined requests like 'research topic and create document' by detecting compound intents and orchestrating sequential tool execution",
          "type": "sub_process",
          "parent_id": "REQ_004",
          "children": [],
          "acceptance_criteria": [
            "Intent classifier detects compound requests containing multiple tool intents",
            "Compound intent returns array of { tool: ToolType, params: object, dependsOn?: string }",
            "ToolChainExecutor orchestrates sequential execution respecting dependencies",
            "First tool result passed as input to dependent tools (e.g., research content \u2192 document)",
            "Chain execution tracks progress with intermediate status updates",
            "UI shows multi-step progress indicator during chain execution",
            "Partial results displayed as each tool completes",
            "Chain aborts on first error with clear error message indicating failed step",
            "Maximum chain depth of 3 tools to prevent runaway costs",
            "Chain cost estimated before execution and shown to user",
            "User can cancel chain execution at any step",
            "Common chains predefined: research+document, research+summarize, generate+edit"
          ],
          "implementation": {
            "frontend": [
              "Create frontend/src/components/tools/ChainProgressIndicator.tsx showing multi-step progress",
              "Create ToolChainPreview component showing planned execution steps",
              "Add cancel button to abort chain execution",
              "Show cost estimate modal before expensive chains",
              "Display partial results as each step completes",
              "Update message UI to handle multi-part tool responses"
            ],
            "backend": [
              "Create frontend/src/lib/tools/chainExecutor.ts for orchestration logic",
              "Implement executeChain(tools: ChainedToolRequest[]): AsyncGenerator<ChainStepResult>",
              "Create dependency resolver to determine execution order",
              "Implement result transformation between tools (research text \u2192 document content)",
              "Add cost calculation based on tool chain composition",
              "Create /api/tools/execute-chain route for server-side orchestration",
              "Implement chain state persistence for long-running chains"
            ],
            "middleware": [
              "Add chain depth validation (max 3 tools)",
              "Implement chain cost limit checking against user budget"
            ],
            "shared": [
              "Define ChainedToolRequest interface with tool, params, dependsOn fields",
              "Define ChainStepResult interface with stepIndex, status, result, error",
              "Define ChainExecutionState enum: 'pending' | 'running' | 'completed' | 'failed' | 'cancelled'",
              "Create PREDEFINED_CHAINS constant with common chain definitions",
              "Define ToolCostEstimate interface with perTool and total costs"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolRouter.multiToolChains",
          "related_concepts": [
            "intent decomposition",
            "task orchestration",
            "pipeline execution",
            "dependency resolution",
            "result passing"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_005",
      "description": "The system must maintain and extend the existing voice input implementation using MediaRecorder and OpenAI Whisper API",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_005.1",
          "description": "Preserve and maintain the AudioRecorder component with 5-minute maximum recording time constraint, ensuring browser MediaRecorder API integration remains functional across supported browsers",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "AudioRecorder component renders microphone button in chat interface",
            "Recording starts when user clicks record button and requests microphone permission",
            "Recording automatically stops after 5 minutes (300 seconds) with user notification",
            "Visual timer displays elapsed recording time in MM:SS format",
            "Recording state transitions correctly: idle \u2192 recording \u2192 processing \u2192 idle",
            "Component detects and uses appropriate MIME type (audio/webm or audio/mp4) based on browser support",
            "Audio chunks are collected via ondataavailable handler during recording",
            "Stop button is visible and functional during active recording",
            "Error handling displays user-friendly message if microphone access is denied",
            "Component cleans up MediaRecorder and audio tracks on unmount"
          ],
          "implementation": {
            "frontend": [
              "AudioRecorder.tsx component at frontend/src/components/chat/AudioRecorder.tsx",
              "Recording button with microphone icon and visual recording indicator",
              "Timer display component showing elapsed time during recording",
              "State management using useState for recordingState, audioBlob, elapsedTime",
              "useEffect hook for 5-minute timeout enforcement",
              "MIME type detection logic: MediaRecorder.isTypeSupported('audio/webm') fallback to 'audio/mp4'",
              "Permission denied error modal/toast component"
            ],
            "backend": [],
            "middleware": [],
            "shared": [
              "MAX_RECORDING_TIME constant = 300000 (5 minutes in milliseconds)",
              "RecordingState type: 'idle' | 'recording' | 'processing' | 'error'",
              "AudioRecorderProps interface with onTranscriptionComplete callback"
            ]
          },
          "testable_properties": [],
          "function_id": "AudioRecorder.preserveRecordingComponent",
          "related_concepts": [
            "MediaRecorder API",
            "WebM/MP4 MIME type detection",
            "Browser compatibility",
            "Audio capture",
            "Recording state management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.2",
          "description": "Maintain the Vercel Blob upload flow that bypasses the 4.5MB serverless function body size limit by storing audio files in Vercel Blob storage before transcription",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Audio blob is uploaded to Vercel Blob storage before transcription request",
            "Upload endpoint returns a secure blob URL for the stored audio file",
            "Blob URL is passed to transcription endpoint instead of raw audio data",
            "Files larger than 4.5MB are successfully handled via blob storage",
            "Upload progress indicator shows during file transfer",
            "Blob is automatically deleted after successful transcription",
            "Blob is deleted on transcription failure after all retries exhausted",
            "Upload endpoint validates file is audio MIME type (audio/webm, audio/mp4, audio/mpeg)",
            "Temporary blob URLs expire after 1 hour for security",
            "Upload errors return appropriate error codes and messages"
          ],
          "implementation": {
            "frontend": [
              "transcription.ts utility at frontend/src/lib/transcription.ts",
              "uploadAudio() function that POSTs audio blob to /api/upload",
              "Upload progress tracking using fetch with ReadableStream or XMLHttpRequest",
              "Loading spinner/progress bar component during upload phase"
            ],
            "backend": [
              "/api/upload/route.ts endpoint for Vercel Blob storage",
              "Use @vercel/blob put() function with { access: 'public' } for temporary storage",
              "Generate unique filename with timestamp and UUID",
              "Return { url: blobUrl, pathname: blobPath } on success",
              "Validate Content-Type header is audio/*"
            ],
            "middleware": [
              "File size validation middleware (max 25MB before upload)",
              "MIME type validation for audio files only"
            ],
            "shared": [
              "MAX_FILE_SIZE constant = 26214400 (25MB in bytes)",
              "ALLOWED_AUDIO_TYPES array = ['audio/webm', 'audio/mp4', 'audio/mpeg', 'audio/wav']",
              "UploadResponse interface { url: string; pathname: string }",
              "TranscriptionError class with code and message properties"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.maintainBlobUploadFlow",
          "related_concepts": [
            "Vercel Blob Storage",
            "Serverless limitations",
            "File upload",
            "Temporary storage",
            "Blob URL management"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.3",
          "description": "Keep the OpenAI Whisper API integration using whisper-1 model for converting audio files to text transcriptions with proper error handling and response formatting",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Transcription endpoint accepts blob URL and fetches audio from Vercel Blob",
            "OpenAI client is instantiated with OPENAI_API_KEY environment variable",
            "Whisper API is called with model: 'whisper-1' parameter",
            "Audio file is converted to proper File object for OpenAI SDK",
            "Transcription text is extracted from response.text field",
            "Empty transcriptions return appropriate error message",
            "Transcription result includes isVoiceTranscription: true flag for message store",
            "Response includes original audio duration metadata when available",
            "API errors are caught and transformed to user-friendly messages",
            "Blob is deleted from Vercel storage after transcription completes"
          ],
          "implementation": {
            "frontend": [
              "transcribeAudio() function in frontend/src/lib/transcription.ts",
              "POST request to /api/transcribe with { blobUrl } body",
              "Handle transcription response and pass to onTranscriptionComplete callback",
              "Display transcribed text in chat input or auto-send as message"
            ],
            "backend": [
              "/api/transcribe/route.ts endpoint",
              "Fetch audio from blob URL using fetch(blobUrl)",
              "Convert response to Buffer then to File object",
              "Call openai.audio.transcriptions.create({ model: 'whisper-1', file: audioFile })",
              "Delete blob using @vercel/blob del() after transcription",
              "Return { text: transcription, duration: audioDuration }"
            ],
            "middleware": [
              "Validate blobUrl is from trusted Vercel Blob domain",
              "Rate limiting middleware for transcription endpoint"
            ],
            "shared": [
              "TranscriptionResponse interface { text: string; duration?: number; isVoiceTranscription: boolean }",
              "WHISPER_MODEL constant = 'whisper-1'",
              "OpenAI client configuration with proper timeout settings"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionAPI.keepWhisperIntegration",
          "related_concepts": [
            "OpenAI Whisper API",
            "Audio transcription",
            "Speech-to-text",
            "whisper-1 model",
            "API response handling"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.4",
          "description": "Support 25 MB maximum file size constraint with 3 retry attempts for failed transcription requests, implementing proper validation and retry logic",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "File size is validated client-side before upload attempt",
            "Files exceeding 25MB display error message without upload attempt",
            "File size validation occurs server-side as secondary check",
            "Failed transcription requests are retried up to 3 times",
            "Each retry attempt is logged with attempt number and error reason",
            "Retry logic distinguishes between retryable and non-retryable errors",
            "Non-retryable errors (invalid file, auth failure) fail immediately",
            "Retryable errors (network timeout, 5xx errors) trigger retry",
            "Final failure after 3 attempts returns comprehensive error message",
            "User sees retry progress indicator showing attempt X of 3"
          ],
          "implementation": {
            "frontend": [
              "validateFileSize() function checking blob.size <= MAX_FILE_SIZE",
              "Error toast/message when file exceeds 25MB: 'Recording too large. Maximum size is 25MB.'",
              "Retry status indicator showing 'Retrying... (attempt 2 of 3)'",
              "transcribeWithRetry() wrapper function implementing retry logic"
            ],
            "backend": [
              "File size validation in /api/upload before blob storage",
              "Retry logic in /api/transcribe with MAX_RETRIES = 3",
              "isRetryableError() helper function checking error types",
              "Exponential backoff between retries (implemented separately)",
              "Logging each attempt with console.log or structured logger"
            ],
            "middleware": [
              "Request body size limit middleware set to 25MB",
              "Content-Length header validation"
            ],
            "shared": [
              "MAX_FILE_SIZE constant = 26214400 (25 * 1024 * 1024 bytes)",
              "MAX_RETRY_ATTEMPTS constant = 3",
              "RetryableErrorCodes array = ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND', '500', '502', '503', '504']",
              "RetryState interface { attempt: number; maxAttempts: number; lastError?: string }"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.supportFileSizeAndRetry",
          "related_concepts": [
            "File size validation",
            "Retry logic",
            "Error recovery",
            "Upload constraints",
            "Resilient API calls"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_005.5",
          "description": "Implement rate limit handling with 10-second base exponential backoff for OpenAI API rate limit errors (429) and network errors with 2-second base backoff",
          "type": "sub_process",
          "parent_id": "REQ_005",
          "children": [],
          "acceptance_criteria": [
            "Rate limit errors (HTTP 429) trigger exponential backoff starting at 10 seconds",
            "Network errors (timeout, connection reset) trigger backoff starting at 2 seconds",
            "Backoff delay doubles with each retry: 10s \u2192 20s \u2192 40s for rate limits",
            "Backoff delay doubles with each retry: 2s \u2192 4s \u2192 8s for network errors",
            "Maximum backoff delay is capped at 60 seconds",
            "Retry-After header from API response is respected when present",
            "User sees 'Rate limited. Retrying in X seconds...' message",
            "Backoff timer is visible to user during wait period",
            "Jitter (\u00b110%) is added to backoff delay to prevent thundering herd",
            "Backoff state resets after successful request"
          ],
          "implementation": {
            "frontend": [
              "Countdown timer component showing seconds until retry",
              "Status message: 'Rate limited by OpenAI. Retrying in {seconds}s...'",
              "Status message: 'Network error. Retrying in {seconds}s...'",
              "Cancel retry button allowing user to abort waiting"
            ],
            "backend": [
              "calculateBackoffDelay() function with exponential calculation",
              "RATE_LIMIT_BASE_DELAY constant = 10000 (10 seconds)",
              "NETWORK_ERROR_BASE_DELAY constant = 2000 (2 seconds)",
              "MAX_BACKOFF_DELAY constant = 60000 (60 seconds)",
              "addJitter() function adding \u00b110% randomization",
              "sleep() utility function using setTimeout with Promise",
              "Check for Retry-After header: parseInt(response.headers.get('Retry-After')) * 1000",
              "Error type detection: isRateLimitError(error) checking for 429 status",
              "Error type detection: isNetworkError(error) checking for network-related codes"
            ],
            "middleware": [],
            "shared": [
              "RATE_LIMIT_BASE_DELAY constant = 10000",
              "NETWORK_ERROR_BASE_DELAY constant = 2000",
              "MAX_BACKOFF_DELAY constant = 60000",
              "JITTER_FACTOR constant = 0.1 (10%)",
              "BackoffConfig interface { baseDelay: number; maxDelay: number; jitter: number }",
              "calculateBackoffDelay(attempt: number, config: BackoffConfig): number function signature",
              "ErrorType enum: 'RATE_LIMIT' | 'NETWORK_ERROR' | 'API_ERROR' | 'VALIDATION_ERROR'"
            ]
          },
          "testable_properties": [],
          "function_id": "TranscriptionService.implementRateLimitBackoff",
          "related_concepts": [
            "Rate limiting",
            "Exponential backoff",
            "429 errors",
            "Network error handling",
            "API throttling"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    },
    {
      "id": "REQ_006",
      "description": "The system must implement comprehensive error handling and cost management across all tools",
      "type": "parent",
      "parent_id": null,
      "children": [
        {
          "id": "REQ_006.1",
          "description": "Define a consistent ToolError interface with code, message, retryable, and suggestedAction fields to standardize error handling across all tool handlers",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "ToolError interface is exported from shared types module (frontend/src/lib/types.ts)",
            "Interface includes required 'code' field typed as ToolErrorCode union type",
            "Interface includes required 'message' field as string for human-readable error description",
            "Interface includes required 'retryable' field as boolean indicating if operation can be retried",
            "Interface includes optional 'suggestedAction' field as string for user guidance",
            "ToolError class extends Error and implements the interface with proper constructor",
            "Interface is compatible with existing TranscriptionError and ChatGenerationError patterns",
            "All new tool handlers (deep research, image generation, document generation) use ToolError",
            "Unit tests verify ToolError construction, serialization, and field access"
          ],
          "implementation": {
            "frontend": [
              "Display suggestedAction in error UI when present",
              "Show retry button only when retryable is true",
              "Color-code errors by severity (rate limit = warning, API error = error)"
            ],
            "backend": [
              "Create ToolError class in shared types module",
              "Implement static factory methods for common error patterns (e.g., ToolError.rateLimited(), ToolError.timeout())",
              "Add toJSON() method for consistent API error response serialization"
            ],
            "middleware": [
              "Create error response helper function that maps ToolError to HTTP status codes",
              "Ensure all tool API routes return consistent error shape { error: string, code: string, retryable: boolean, suggestedAction?: string }"
            ],
            "shared": [
              "Define ToolErrorCode type: 'RATE_LIMIT' | 'INVALID_REQUEST' | 'API_ERROR' | 'TIMEOUT' | 'NETWORK' | 'CONFIG_ERROR' | 'QUOTA_EXCEEDED'",
              "Create HTTP status code mapping: Record<ToolErrorCode, number>",
              "Define ToolError interface and class in frontend/src/lib/types.ts"
            ]
          },
          "testable_properties": [],
          "function_id": "ToolError.interface",
          "related_concepts": [
            "error handling",
            "TypeScript interfaces",
            "error codes",
            "retry logic",
            "user feedback"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.2",
          "description": "Support comprehensive error codes (RATE_LIMIT, INVALID_REQUEST, API_ERROR, TIMEOUT) with appropriate HTTP status mapping and retry configuration per code",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "RATE_LIMIT code maps to HTTP 429 and is marked retryable with 10-second base delay",
            "INVALID_REQUEST code maps to HTTP 400 and is NOT retryable",
            "API_ERROR code maps to HTTP 500/502/503 and is retryable for 5xx errors only",
            "TIMEOUT code maps to HTTP 504 and is retryable with exponential backoff",
            "Each error code has a default suggestedAction message defined",
            "Error codes cover all OpenAI API error responses (401, 429, 500-504)",
            "Tool-specific error codes are supported (e.g., IMAGE_GENERATION_FAILED, RESEARCH_TIMEOUT)",
            "Error code configuration is centralized in a single module for consistency",
            "Each tool handler maps provider-specific errors to standardized ToolErrorCode"
          ],
          "implementation": {
            "frontend": [
              "Create error code to user message mapping for friendly error display",
              "Implement error notification component that renders based on error code severity",
              "Show countdown timer for rate limit errors with retry ETA"
            ],
            "backend": [
              "Create ErrorConfig object mapping each code to { httpStatus, retryable, baseDelayMs, maxRetries, defaultMessage }",
              "Implement mapOpenAIError() function to convert OpenAI SDK errors to ToolError",
              "Add TIMEOUT handling with configurable timeout values per tool (e.g., 30s for images, 10min for deep research)"
            ],
            "middleware": [
              "Create withErrorHandling() wrapper for tool API routes to standardize error response format",
              "Log error codes and messages for monitoring and debugging",
              "Track error rates by code for observability"
            ],
            "shared": [
              "Define ERROR_CONFIG constant with per-code configuration",
              "Export helper functions: isRetryable(code), getHttpStatus(code), getDefaultMessage(code)",
              "Create suggested action messages: { RATE_LIMIT: 'Please wait and try again', TIMEOUT: 'The operation took too long, try a simpler request' }"
            ]
          },
          "testable_properties": [],
          "function_id": "ErrorCodes.enumeration",
          "related_concepts": [
            "HTTP status codes",
            "error classification",
            "retry policies",
            "OpenAI API errors",
            "rate limiting"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.3",
          "description": "Use o4-mini-deep-research (~$3/query) as the default model instead of o3-deep-research (~$30/query) for cost optimization while allowing user override",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "Deep research handler defaults to 'o4-mini-deep-research-2025-06-26' model",
            "User can explicitly request 'thorough' mode which uses 'o3-deep-research-2025-06-26'",
            "Intent classifier extracts depth preference from natural language (e.g., 'quick research' vs 'in-depth analysis')",
            "API route accepts optional 'depth' parameter with values 'quick' | 'thorough'",
            "Model selection is logged for cost tracking and analytics",
            "Environment variable DEEP_RESEARCH_DEFAULT_MODEL allows override of default",
            "Cost estimates are calculated before execution: $3 for quick, $30 for thorough",
            "Unit tests verify correct model selection based on depth parameter"
          ],
          "implementation": {
            "frontend": [
              "Add depth selector UI in advanced options (default: quick, optional: thorough)",
              "Show cost indicator badge when thorough mode is selected ($$$)",
              "Remember user's preferred depth setting in local storage"
            ],
            "backend": [
              "Create DEEP_RESEARCH_MODELS constant mapping depth to model name",
              "Implement getDeepResearchModel(depth?: 'quick' | 'thorough') helper function",
              "Log model selection with estimated cost in analytics events",
              "Add /api/tools/deep-research route with depth parameter support"
            ],
            "middleware": [
              "Validate depth parameter is 'quick' or 'thorough' if provided",
              "Add rate limiting per model tier (stricter limits for o3)"
            ],
            "shared": [
              "Define DeepResearchDepth type: 'quick' | 'thorough'",
              "Create DEEP_RESEARCH_PRICING constant: { quick: 3, thorough: 30 }",
              "Define model name constants with versioned model identifiers"
            ]
          },
          "testable_properties": [],
          "function_id": "CostOptimization.defaultModel",
          "related_concepts": [
            "cost management",
            "model selection",
            "deep research API",
            "user preferences",
            "budget controls"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.4",
          "description": "Implement caching for common image generation requests to reduce API costs and improve response time for repeated prompts",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "Image generation requests are hashed by prompt + parameters (size, quality, style)",
            "Cache lookup occurs before making API call to gpt-image-1.5",
            "Cached images are stored in Vercel Blob with 7-day TTL",
            "Cache hit returns existing blob URL within 100ms",
            "Cache key includes normalized prompt (lowercase, trimmed, no extra whitespace)",
            "Cache stores metadata: prompt, parameters, createdAt, accessCount, blobUrl",
            "Cache statistics are logged: hits, misses, hit rate percentage",
            "Similar prompts (edit distance < 10%) can optionally match cached images",
            "User can bypass cache with 'regenerate' flag to force new generation"
          ],
          "implementation": {
            "frontend": [
              "Show cache indicator icon on images served from cache",
              "Add 'Regenerate' button to force new image generation bypassing cache",
              "Display estimated cost savings from cache hits"
            ],
            "backend": [
              "Create ImageCacheService class with get(), set(), and invalidate() methods",
              "Implement prompt normalization: lowercase, trim, collapse whitespace, remove punctuation",
              "Generate cache key as SHA-256 hash of normalized prompt + JSON.stringify(params)",
              "Store cache index in Redis/KV store with blob URLs as values",
              "Implement LRU eviction when cache size exceeds limit (e.g., 1000 entries)",
              "Add /api/tools/generate-image route with cache integration"
            ],
            "middleware": [
              "Add X-Cache-Status header to image responses (HIT/MISS/BYPASS)",
              "Log cache performance metrics for monitoring"
            ],
            "shared": [
              "Define ImageCacheEntry interface: { promptHash: string, blobUrl: string, params: ImageParams, createdAt: Date, accessCount: number }",
              "Create normalizePrompt() utility function",
              "Define CACHE_CONFIG: { ttlDays: 7, maxEntries: 1000, similarityThreshold: 0.9 }"
            ]
          },
          "testable_properties": [],
          "function_id": "ImageCache.implementation",
          "related_concepts": [
            "caching",
            "image generation",
            "cost reduction",
            "content-addressable storage",
            "cache invalidation"
          ],
          "category": "functional"
        },
        {
          "id": "REQ_006.5",
          "description": "Display estimated costs to users before tool execution for transparency and budget awareness, with optional confirmation for expensive operations",
          "type": "sub_process",
          "parent_id": "REQ_006",
          "children": [],
          "acceptance_criteria": [
            "Cost estimation is calculated before tool execution based on tool type and parameters",
            "Estimated cost is displayed to user in UI before confirming action",
            "Operations over $5 threshold show confirmation dialog with cost breakdown",
            "Cost estimates include: base cost, per-token estimate (if applicable), and total range",
            "Deep research shows $3 (quick) or $30 (thorough) estimate",
            "Image generation shows $0.01-$0.17 based on quality setting",
            "Document generation shows $0.05 base estimate",
            "User can set personal budget limit in settings that triggers warnings",
            "Cost history is tracked and displayed in user dashboard",
            "Cumulative session cost is shown in UI footer/status bar"
          ],
          "implementation": {
            "frontend": [
              "Create CostEstimateDisplay component showing price badge (e.g., '$3.00 est.')",
              "Implement CostConfirmationDialog for expensive operations with 'Proceed' / 'Cancel' buttons",
              "Add session cost counter in application header/footer",
              "Create CostHistoryPanel showing recent operations and their costs",
              "Add budget limit setting in user preferences with warning threshold",
              "Color-code cost badges: green (<$1), yellow ($1-$10), red (>$10)"
            ],
            "backend": [
              "Create CostEstimator service with estimateCost(tool, params) method",
              "Define pricing constants for each tool and model combination",
              "Track actual costs after API responses (compare estimated vs actual)",
              "Store cost history in user session or database",
              "Implement /api/cost/estimate endpoint for pre-flight cost checks"
            ],
            "middleware": [
              "Add cost validation middleware that checks against user budget limits",
              "Return 402 Payment Required if operation exceeds user's budget limit",
              "Include X-Estimated-Cost and X-Actual-Cost headers in tool responses"
            ],
            "shared": [
              "Define TOOL_PRICING constant with per-tool cost formulas",
              "Create CostEstimate interface: { tool: string, estimatedMin: number, estimatedMax: number, currency: 'USD' }",
              "Define formatCost() utility for consistent currency display",
              "Create CONFIRMATION_THRESHOLD constant (default $5.00)"
            ]
          },
          "testable_properties": [],
          "function_id": "CostEstimation.display",
          "related_concepts": [
            "cost transparency",
            "user confirmation",
            "budget management",
            "pricing display",
            "UX patterns"
          ],
          "category": "functional"
        }
      ],
      "acceptance_criteria": [],
      "implementation": null,
      "testable_properties": [],
      "function_id": null,
      "related_concepts": [],
      "category": "functional"
    }
  ],
  "metadata": {
    "source": "agent_sdk_decomposition",
    "research_length": 29166,
    "decomposition_stats": {
      "requirements_found": 7,
      "subprocesses_expanded": 35,
      "total_nodes": 42,
      "extraction_time_ms": 27248,
      "expansion_time_ms": 646797
    }
  }
}